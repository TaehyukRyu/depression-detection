"""
ì¶”ë¡ (Inference) ë©”ì¸ ëª¨ë“ˆ
- í…ìŠ¤íŠ¸ + ìŒì„± ì…ë ¥ì„ ë°›ì•„ ìš°ìš¸ ì‹ í˜¸ ì˜ˆì¸¡
"""

import torch
import numpy as np
from preprocessing import AudioPreprocessor, TextPreprocessor, preprocess_input
from model import MultiModalClassifier, load_model


class DepressionDetector:
    """ìš°ìš¸ì¦ ê°ì§€ ì¶”ë¡  í´ë˜ìŠ¤"""
    
    def __init__(self, model_path, device='cuda'):
        """
        Args:
            model_path: í•™ìŠµëœ ëª¨ë¸ .pt íŒŒì¼ ê²½ë¡œ
            device: 'cuda' or 'cpu'
        """
        self.device = device if torch.cuda.is_available() else 'cpu'
        
        # ë ˆì´ë¸” ì •ì˜
        self.label_names = ['ê¸°ì¨', 'ë‹¹í™©', 'ë¶„ë…¸', 'ë¶ˆì•ˆ', 'ìƒì²˜', 'ìŠ¬í””']
        self.depression_classes = [3, 4, 5]  # ë¶ˆì•ˆ, ìƒì²˜, ìŠ¬í””
        
        # ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        print("ğŸ“Œ ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì¤‘...")
        self.audio_processor = AudioPreprocessor(
            n_mfcc=30,
            sr=16000,
            max_time_steps=8144
        )
        self.text_processor = TextPreprocessor(
            model_name='klue/roberta-base',
            max_length=512,
            device=self.device
        )
        
        # ëª¨ë¸ ë¡œë“œ
        print("ğŸ“Œ ëª¨ë¸ ë¡œë“œ ì¤‘...")
        self.model = load_model(
            checkpoint_path=model_path,
            num_class=len(self.label_names),
            device=self.device
        )
        
        print(f"âœ… DepressionDetector ì´ˆê¸°í™” ì™„ë£Œ (device: {self.device})")
    
    def predict(self, text, audio_path):
        """
        í…ìŠ¤íŠ¸ + ìŒì„± ì…ë ¥ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰
        
        Args:
            text: ì…ë ¥ í…ìŠ¤íŠ¸ (str)
            audio_path: ìŒì„± íŒŒì¼ ê²½ë¡œ (str)
            
        Returns:
            dict: {
                'label': ì˜ˆì¸¡ ë ˆì´ë¸” (str),
                'label_id': ë ˆì´ë¸” ID (int),
                'probabilities': ê° í´ë˜ìŠ¤ë³„ í™•ë¥  (dict),
                'is_depression': ìš°ìš¸ ì‹ í˜¸ ì—¬ë¶€ (bool),
                'depression_prob': ìš°ìš¸ ì‹ í˜¸ í™•ë¥  (float),
                'confidence': ì˜ˆì¸¡ ì‹ ë¢°ë„ (float)
            }
        """
        # 1. ì „ì²˜ë¦¬
        inputs = preprocess_input(
            text=text,
            audio_path=audio_path,
            audio_processor=self.audio_processor,
            text_processor=self.text_processor
        )
        
        # 2. ì…ë ¥ ë°ì´í„°ë¥¼ deviceë¡œ ì´ë™
        input_ids = inputs['input_ids'].to(self.device)
        attention_mask = inputs['attention_mask'].to(self.device)
        phq9_sim = inputs['phq9_similarity'].to(self.device)
        mfcc = inputs['mfcc'].to(self.device)
        
        # 3. ëª¨ë¸ ì¶”ë¡ 
        self.model.eval()
        with torch.no_grad():
            logits = self.model(input_ids, attention_mask, phq9_sim, mfcc)
            probs = torch.softmax(logits, dim=1)
            pred_id = torch.argmax(probs, dim=1).item()
            pred_prob = probs[0, pred_id].item()
        
        # 4. ê²°ê³¼ ì •ë¦¬
        probs_dict = {
            self.label_names[i]: float(probs[0, i].item())
            for i in range(len(self.label_names))
        }
        
        # ìš°ìš¸ ì‹ í˜¸ ì—¬ë¶€ íŒë‹¨
        is_depression = pred_id in self.depression_classes
        
        # ìš°ìš¸ ì‹ í˜¸ í™•ë¥  (ë¶ˆì•ˆ + ìƒì²˜ + ìŠ¬í”” í™•ë¥  í•©)
        depression_prob = sum([
            probs[0, cls_id].item() 
            for cls_id in self.depression_classes
        ])
        
        return {
            'label': self.label_names[pred_id],
            'label_id': pred_id,
            'probabilities': probs_dict,
            'is_depression': is_depression,
            'depression_prob': depression_prob,
            'confidence': pred_prob
        }
    
    def predict_batch(self, text_list, audio_path_list):
        """
        ë°°ì¹˜ ì˜ˆì¸¡ (ì—¬ëŸ¬ ì…ë ¥ì„ í•œ ë²ˆì— ì²˜ë¦¬)
        
        Args:
            text_list: í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            audio_path_list: ìŒì„± íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            list of dict: ê° ì…ë ¥ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼
        """
        results = []
        
        for text, audio_path in zip(text_list, audio_path_list):
            result = self.predict(text, audio_path)
            results.append(result)
        
        return results
    
    def explain_prediction(self, result):
        """
        ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‚¬ëŒì´ ì½ê¸° ì‰½ê²Œ ì„¤ëª…
        
        Args:
            result: predict() í•¨ìˆ˜ì˜ ë°˜í™˜ê°’
            
        Returns:
            str: ì„¤ëª… í…ìŠ¤íŠ¸
        """
        label = result['label']
        confidence = result['confidence']
        is_depression = result['is_depression']
        depression_prob = result['depression_prob']
        
        explanation = f"""
        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘        ì˜ˆì¸¡ ê²°ê³¼                      â•‘
        â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
        â•‘ ì˜ˆì¸¡ ê°ì •: {label} ({confidence:.1%})
        â•‘ ìš°ìš¸ ì‹ í˜¸: {'âš ï¸  ì˜ˆ (ì£¼ì˜ í•„ìš”)' if is_depression else 'âœ… ì•„ë‹ˆì˜¤'}
        â•‘ ìš°ìš¸ í™•ë¥ : {depression_prob:.1%}
        â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
        â•‘ í´ë˜ìŠ¤ë³„ í™•ë¥                           â•‘
        """
        
        for emotion, prob in sorted(result['probabilities'].items(), 
                                   key=lambda x: x[1], reverse=True):
            bar = 'â–ˆ' * int(prob * 20)
            explanation += f"â•‘  {emotion:4s}: {bar:20s} {prob:.1%}\n"
        
        explanation += "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        
        if is_depression and depression_prob > 0.7:
            explanation += f"""
        
        âš ï¸  ê²½ê³ : ë†’ì€ ìš°ìš¸ ì‹ í˜¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.
        ì „ë¬¸ê°€ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
        """
        
        return explanation


def main():
    """ì‚¬ìš© ì˜ˆì‹œ"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ìš°ìš¸ì¦ ì¡°ê¸° ê°ì§€ ì¶”ë¡ ')
    parser.add_argument('--model', type=str, required=True, 
                       help='ëª¨ë¸ .pt íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--text', type=str, required=True, 
                       help='ì…ë ¥ í…ìŠ¤íŠ¸')
    parser.add_argument('--audio', type=str, required=True, 
                       help='ìŒì„± íŒŒì¼ ê²½ë¡œ (.mp3 ë˜ëŠ” .wav)')
    parser.add_argument('--device', type=str, default='cuda', 
                       choices=['cuda', 'cpu'], help='ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤')
    
    args = parser.parse_args()
    
    # 1. Detector ì´ˆê¸°í™”
    detector = DepressionDetector(
        model_path=args.model,
        device=args.device
    )
    
    # 2. ì˜ˆì¸¡ ìˆ˜í–‰
    print("\nğŸ” ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
    result = detector.predict(
        text=args.text,
        audio_path=args.audio
    )
    
    # 3. ê²°ê³¼ ì¶œë ¥
    print(detector.explain_prediction(result))
    
    # 4. JSON í˜•íƒœë¡œë„ ì¶œë ¥
    import json
    print("\nğŸ“„ JSON ê²°ê³¼:")
    print(json.dumps(result, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
    print("="*60)
    print("ì¶”ë¡  ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("="*60)
    print("\nì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ:")
    print("""
    python inference.py \\
        --model models/phase3_six_label_all_text_phq9_multimodal.pt \\
        --text "ìš”ì¦˜ ë„ˆë¬´ ìš°ìš¸í•˜ê³  ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ì–´ìš”" \\
        --audio data/sample.mp3 \\
        --device cuda
    """)
    print("\në˜ëŠ” Python ì½”ë“œì—ì„œ:")
    print("""
    from inference import DepressionDetector
    
    detector = DepressionDetector('models/multimodal.pt')
    result = detector.predict(
        text="ìš”ì¦˜ ë„ˆë¬´ ìš°ìš¸í•˜ê³  ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ì–´ìš”",
        audio_path="data/sample.mp3"
    )
    print(result)
    """)
